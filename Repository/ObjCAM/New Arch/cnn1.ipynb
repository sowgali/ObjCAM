{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Class 0...Data/0/\n",
      "Loading Class 1...Data/1/\n"
     ]
    }
   ],
   "source": [
    "# Reading the input images and putting them into a numpy array\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "height = 150\n",
    "width = 150\n",
    "channels = 3\n",
    "classes = 2\n",
    "n_inputs = height * width * channels\n",
    "\n",
    "for i in range(0, classes, 1):\n",
    "    path = \"Data/{}/\".format(i)\n",
    "    print(\"Loading Class {}...\".format(i)+path)\n",
    "    Class=os.listdir(path)\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a)\n",
    "            size_image = cv2.resize(image, (height, width))\n",
    "            data.append(np.array(size_image))\n",
    "            labels.append(i)\n",
    "        except AttributeError:\n",
    "            print(\"Attribut Error\")\n",
    "            \n",
    "Cells=np.array(data)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize the order of the input images\n",
    "s=np.arange(Cells.shape[0])\n",
    "np.random.seed(classes)\n",
    "np.random.shuffle(s)\n",
    "Cells=Cells[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the images into train and validation sets\n",
    "(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\n",
    "X_train = X_train.astype('float32')/255 \n",
    "X_val = X_val.astype('float32')/255\n",
    "(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "#Using one hot encoding for the train and validation labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, classes)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 146, 146, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 71, 71, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 39200)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               10035456  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 10,041,826\n",
      "Trainable params: 10,041,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(rate=0.25))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(rate=0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(classes, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compilation of the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 14s 1s/step - loss: 4.4567 - accuracy: 0.5673 - val_loss: 0.7943 - val_accuracy: 0.6092\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.6441 - accuracy: 0.7163 - val_loss: 0.3812 - val_accuracy: 0.9770\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.2610 - accuracy: 0.9198 - val_loss: 0.2422 - val_accuracy: 0.9540\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.1319 - accuracy: 0.9628 - val_loss: 0.0939 - val_accuracy: 0.9770\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0665 - accuracy: 0.9685 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0568 - accuracy: 0.9828 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0493 - val_accuracy: 0.9655\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0287 - accuracy: 0.9885 - val_loss: 0.1751 - val_accuracy: 0.9080\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0621 - val_accuracy: 0.9885\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.0260 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 10\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16  1 38 ...  6  7 10]\n"
     ]
    }
   ],
   "source": [
    "#Load test data\n",
    "y_test=pd.read_csv(\"./TrafficSigns_dataset/Test.csv\")\n",
    "labels=y_test['Path'].values\n",
    "y_test=y_test['ClassId'].values\n",
    "\n",
    "print (y_test)\n",
    "\n",
    "data=[]\n",
    "\n",
    "for f in labels:\n",
    "    image=cv2.imread('./TrafficSigns_dataset/test/'+f.replace('Test/', ''))\n",
    "    image_from_array = Image.fromarray(image, 'RGB')\n",
    "    size_image = image_from_array.resize((height, width))\n",
    "    data.append(np.array(size_image))\n",
    "\n",
    "X_test=np.array(data)\n",
    "X_test = X_test.astype('float32')/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict output for test examples\n",
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9355502771179731\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "if(len(pred) == len(y_test)):\n",
    "    for i in range(0, len(pred)):\n",
    "        if (pred[i] == y_test[i]):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "\n",
    "test_acc = correct/(correct+incorrect)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"WhiteBox_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3777c0344701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclass_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrad_CAM_map\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_CAM_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgrad_CAM_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/sowrya/DATA/My/Research/New Arch/utils.py\u001b[0m in \u001b[0;36mgrad_CAM_plus\u001b[0;34m(filename, label_id, output_filename, model)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlabel_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "output_filename = \"output.jpeg\"\n",
    "image_filename = \"Test.jpg\"\n",
    "class_label = 0\n",
    "grad_CAM_map= utils.grad_CAM_plus(image_filename, class_label, output_filename, model)\n",
    "grad_CAM_plus(filename, label_id, output_filename, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    resized_img = skimage.transform.resize(crop_img, (150, 150))\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_CAM_plus(filename, label_id, output_filename, model):\n",
    "    \n",
    "    img1 = load_image(filename)\n",
    "    model(img1)\n",
    "    cost = tf.nn.softmax(model.get_layer(name=\"dense_1\"))\n",
    "\n",
    "    target_conv_layer = model.get_layer(name=\"conv2d_1\").output\n",
    "    target_conv_layer_grad = tf.gradients(cost, target_conv_layer)[0]\n",
    "\n",
    "    first_derivative = tf.exp(cost)[0][label_id]*target_conv_layer_grad\n",
    "\n",
    "    second_derivative = tf.exp(cost)[0][label_id]*target_conv_layer_grad*target_conv_layer_grad \n",
    "\n",
    "    triple_derivative = tf.exp(cost)[0][label_id]*target_conv_layer_grad*target_conv_layer_grad*target_conv_layer_grad  \n",
    "\n",
    "    output = [0,0]\n",
    "    output[label_id] = 1.0\n",
    "    output = np.array(output)\n",
    "    print (label_id)\n",
    "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = sess.run([target_conv_layer, first_derivative, second_derivative, triple_derivative], feed_dict={input_image:[img1], label_index:label_id, label_vector: output.reshape((1,-1))})\n",
    "\n",
    "    global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n",
    "\n",
    "    alpha_num = conv_second_grad[0]\n",
    "    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num/alpha_denom\n",
    "\n",
    "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "    alphas_thresholding = np.where(weights, alphas, 0.0)\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
    "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
    "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    deep_linearization_weights = np.sum((weights*alphas).reshape((-1,conv_first_grad[0].shape[2])),axis=0)\n",
    "    grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n",
    "    cam = np.maximum(grad_CAM_map, 0)\n",
    "    cam = cam / np.max(cam) # scale 0 to 1.0   \n",
    "    print(\"\\nCam Shape Before:\")\n",
    "    print(cam.shape)\n",
    "    cam = resize(cam, (150,150))\n",
    "    gb = guided_BP([img1], label_id)\n",
    "    visualize(img1, cam, output_filename, gb) \n",
    "    return cam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
